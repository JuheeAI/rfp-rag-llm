# ë°œí‘œ ìë£Œ
- [RFP ë¶„ì„ì„ ìœ„í•œ RAG ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ ì‹œìŠ¤í…œ]https://drive.google.com/file/d/16zEA8xrlwJu33fQ7QpyYIQ4PojXhSX0L/view?usp=sharing

# 4íŒ€ í˜‘ì—…ì¼ì§€
- ìœ¤ìŠ¹í˜¸
    LINK: [https://www.notion.so/yoonsnowdev/1d6219b29fc380a0b152d5457e2f4839?pvs=4](https://www.notion.so/1d6219b29fc380a0b152d5457e2f4839?pvs=21)
- ê¹€ë¯¼ê²½
    LINK: [https://endurable-ice-f3c.notion.site/Daily-237218930d5e80d0b795dbfe1b9637b8](https://www.notion.so/237218930d5e80d0b795dbfe1b9637b8?pvs=21)
- ë°©ì§€í˜•
    LINK: [https://www.notion.so/1fbf89eac2f1805e8b09e102fc1a73a9?source=copy_link](https://www.notion.so/1fbf89eac2f1805e8b09e102fc1a73a9?pvs=21)
- ì†ì£¼í¬
    LINK: [https://www.notion.so/23846e2fcad880189b0ad50df0aea229?source=copy_link](https://www.notion.so/23846e2fcad880189b0ad50df0aea229?pvs=21)
- ì‹ í•œí˜¸
    LINK: [https://www.notion.so/_4-_-237c6f869cf680c28105e0b9018cfa6f?source=copy_link](https://www.notion.so/237c6f869cf680c28105e0b9018cfa6f?pvs=21)
- ì´ìŠ¹ì¢…
    LINK: [https://www.notion.so/237e3ffbb65580fa9e19debd13719714?source=copy_link](https://www.notion.so/237e3ffbb65580fa9e19debd13719714?pvs=21)

# RFP ê¸°ë°˜ RAG ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸

## ì‚¬ìš©í•´ë³´ê¸°
ì•„ë˜ ì£¼ì†Œì—ì„œ ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
â¡ **[Bidding Mate ì›¹ ë°ëª¨](http://34.68.253.209:8501/)**

### ì‚¬ìš© ë°©ë²•
1. **ëª¨ë¸ ì„ íƒ**
	- ì‚¬ì´ë“œë°”ì—ì„œ `Open Source` ë˜ëŠ” `OpenAI` ëª¨ë¸ ì¤‘ ì„ íƒ
2. **OpenAI ëª¨ë¸ ì‚¬ìš© ì‹œ**
	- ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥
3. **ì§ˆë¬¸ ì…ë ¥**
	- ì±„íŒ…ì°½ì— ë¶„ì„í•˜ê³  ì‹¶ì€ RFP ê´€ë ¨ ì§ˆë¬¸ ì…ë ¥
4. **Reference Check ì˜µì…˜**
	- ê·¼ê±° ë¬¸ì„œ í™•ì¸ì´ í•„ìš”í•˜ë©´ Reference Check í™œì„±í™”

### ì˜ˆì‹œ ì‚¬ì§„
![alt text](data/image.png)
![alt text](data/image-1.png)

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”
ì´ í”„ë¡œì íŠ¸ëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP) ë° ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸(LLM) ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ 
ê¸°ì—… ë° ì •ë¶€ì˜ ë³µì¡í•œ í˜•íƒœì˜ ì œì•ˆìš”ì²­ì„œ(RFP)ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë¶„ì„Â·ì¶”ì¶œÂ·ìš”ì•½í•˜ì—¬  
B2G ì…ì°°ì§€ì› ì „ë¬¸ ì»¨ì„¤íŒ… ìŠ¤íƒ€íŠ¸ì—… 'ì…ì°°ë©”ì´íŠ¸'ì˜ ì„œë¹„ìŠ¤ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

---

## 2. í”„ë¡œì íŠ¸ ë°°ê²½
- **ë„ë©”ì¸ íŠ¹ì„±**: RFPëŠ” ìˆ˜ì‹­~ìˆ˜ë°± í˜ì´ì§€ì— ë‹¬í•˜ë©°, í‘œÂ·ì´ë¯¸ì§€Â·í…ìŠ¤íŠ¸ê°€ í˜¼í•©ëœ í˜•íƒœ
- **ë¹„ì¦ˆë‹ˆìŠ¤ ë‹ˆì¦ˆ**:
	- í•˜ë£¨ ìˆ˜ë°± ê±´ì˜ ê³µê³µ ì…ì°° ê³µê³  ì¤‘ ê³ ê°ì‚¬ ë§ì¶¤í˜• ê¸°íšŒë¥¼ ë¹ ë¥´ê²Œ íƒìƒ‰
	- ì£¼ìš” ìš”êµ¬ ì¡°ê±´, ëŒ€ìƒ ê¸°ê´€, ì˜ˆì‚°, ì œì¶œ ë°©ì‹ ë“± í•µì‹¬ ì •ë³´ íŒŒì•…
- **ëª©í‘œ**:
	- ì‚¬ìš©ìì˜ ì§ˆì˜ì— ê¸°ë°˜í•˜ì—¬ RFPì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì‹ ì†Â·ì •í™•í•˜ê²Œ ê²€ìƒ‰
	- í•„ìš”í•œ ê²½ìš° RFP ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì œê³µ
	- ì‚¬ë‚´ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„
	
---

## 3. ë°ì´í„° êµ¬ì„±
- **ë¬¸ì„œ**: ì‹¤ì œ RFP ë¬¸ì„œ 100ê±´
- **í˜•íƒœ**:
	- PDF ì›ë¬¸ + ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°
	- í‘œ, ì´ë¯¸ì§€, ë³¸ë¬¸ í…ìŠ¤íŠ¸ í¬í•¨
- **ë©”íƒ€ë°ì´í„° ì¼ë¶€**:
	- ì‚¬ì—…ëª…
	- ì˜ˆì‚°
	- ë°œì£¼ì²˜
	- ì œì¶œ ê¸°í•œ
	- ì…ì°° ë°©ì‹
	
--- 

## 4. ì‹œìŠ¤í…œ ëª©í‘œ
1. **RFP ë¬¸ì„œ ë¶„ì„**
	- OCR ì‹œë„(ë³´ë¥˜): ë¬¸ì„œ ë‚´ ì´ë¯¸ì§€/ìŠ¤ìº” ì˜ì—­ì— ëŒ€í•´ OCRì„ ì‹œë„í–ˆìœ¼ë‚˜ ìµœì¢… ì ìš©ì€ ì œì™¸
	- í‘œ ë°ì´í„°í™”: í‘œ(Table)ë§Œ ë°ì´í„°í™”í•˜ì—¬ êµ¬ì¡°í™” ì‘ì—…ì— í™œìš©
	- ê²°ê³¼ë¬¼ í˜•íƒœ: ì „ì²˜ë¦¬ ê²°ê³¼ëŠ” **êµ¬ì¡°í™”ëœ JSON**ìœ¼ë¡œ ì €ì¥/ì‚¬ìš©
2. **Q&A ê¸°ëŠ¥ êµ¬í˜„**
	- ì‚¬ìš©ì ì§ˆì˜ -> ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰(Retriever) -> LLM ê¸°ë°˜ ë‹µë³€ ìƒì„±(Generator)
3. **ìš”ì•½ ì„œë¹„ìŠ¤**
	- ì¥ë¬¸ RFPë¥¼ ìš”ì•½í•˜ì—¬ ì¤‘ìš”í•œ í•­ëª©ë§Œ ë¹ ë¥´ê²Œ í™•ì¸ ê°€ëŠ¥
4. **ì„±ëŠ¥ í‰ê°€**
	- Retriever ë° Generator ê°ê°ì˜ ì„±ëŠ¥ ì¸¡ì •
	- Faithfulness, Correctness ë“± ì§€í‘œ ê¸°ë°˜ í‰ê°€
	
---

## 5. ì‚¬ìš© ê¸°ìˆ 
- **ì „ì²˜ë¦¬**: pyautogui, pyperclip, pytesseract, pdf2image (OCR ì‹œë„, ìµœì¢… ì œì™¸)
- **ì„ë² ë”© ëª¨ë¸**: KoSimCSE, KR-SBERT, ê¸°íƒ€ í•œêµ­ì–´ SBERT ê³„ì—´
- **DB/ì¸ë±ìŠ¤**: FAISS (**LangChain FAISS** ì‚¬ìš©)
- **LLM**: Hugging Face Transformers(Midm-Base), OpenAI API
- **í”„ë ˆì„ì›Œí¬**: LangChain, LangGraph
- **í‰ê°€**: LangSmith, LLM-as-a-judge ë°©ì‹
- **í”„ë¡ íŠ¸ì—”ë“œ**: Streamlit
- **ë°±ì—”ë“œ/API**: FastAPI

---

## 6. ì‹¤í—˜ ë° í‰ê°€ ê³„íš
1. **Retriever ì‹¤í—˜**
	- ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ ë¹„êµ
	- LangChain FAISS ê¸°ë°˜ Dense Retrieval ì‚¬ìš© (BM25/HybridëŠ” ì¶”í›„ ì‹¤í—˜ í•­ëª©ìœ¼ë¡œ ë³´ë¥˜)
	- top-k ë° chunk size ìµœì í™”
2. **Generator ì‹¤í—˜**
	- HuggingFace ê¸°ë°˜ LLM vs OpenAI GPT ëª¨ë¸
	- í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° ê·¼ê±° ì¸ìš©ë¥  ì¸¡ì •
3. **í‰ê°€ ì§€í‘œ**
	- Faithfulness / Correctness (5ì  ì²™ë„)
	- ì‘ë‹µ ê·¼ê±° í¬í•¨ ì—¬ë¶€
4. **ë³´ê³ ì„œ/ë°œí‘œ**
	- ì‹¤í—˜ ê³¼ì •, ì˜ì‚¬ê²°ì •, í‰ê°€ ê²°ê³¼ë¥¼ ë³´ê³ ì„œì™€ ë°œí‘œ ìë£Œë¡œ ì œì¶œ
	
---
	
## 7. ê¸°ëŒ€ íš¨ê³¼
- **ì—…ë¬´ íš¨ìœ¨ í–¥ìƒ**: RFP ë¶„ì„Â·ê²€ìƒ‰Â·ìš”ì•½ ìë™í™”
- **ê³ ê° ë§Œì¡±ë„ ê°œì„ **: ë§ì¶¤í˜• ì…ì°° ê¸°íšŒ ì œê³µ
- **ì‚¬ë‚´ ê¸°ìˆ  ìì‚° í™•ë³´**: RAG ì‹œìŠ¤í…œ ìš´ì˜ ê²½í—˜ ë° í‰ê°€ ë°ì´í„° ì¶•ì 

---

## 8.í”„ë¡œì íŠ¸ ì‚°ì¶œë¬¼

```text
ğŸ“‚ í”„ë¡œì íŠ¸ ë£¨íŠ¸
â”œâ”€â”€ ğŸ“‚ data                # ë°ì´í„° ì €ì¥ì†Œ (í‰ê°€ ë°ì´í„°)
â”‚
â”œâ”€â”€ ğŸ“‚ notebook            # EDA ë° ë¶„ì„ìš© Jupyter Notebook
â”‚   â””â”€â”€ EDA.ipynb
â”‚
â”œâ”€â”€ ğŸ“‚ scripts             # ì „ì²˜ë¦¬ ë° í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ëª¨ìŒ
â”‚   â”œâ”€â”€ AB_pipeline_eval.py             # A/B í‰ê°€ ë¬¸ì„œ ì‘ì„± ì½”ë“œ (LangSmith ê¸°ë°˜ ì„±ëŠ¥ í‰ê°€)
â”‚   â”œâ”€â”€ hwp_to_pdf.py                   # HWP â†’ PDF ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ preprocess.py                   # ë¬¸ì„œ ì „ì²˜ë¦¬ ë° JSON ìƒì„±
â”‚
â”œâ”€â”€ ğŸ“‚ src                 # RAG ì‹œìŠ¤í…œ í•µì‹¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ A_embedding.py                 # ì„ë² ë”© ìƒì„±
â”‚   â”œâ”€â”€ A_indexing.py                  # ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±
â”‚   â”œâ”€â”€ A_retriever.py                 # Retriever (ê²€ìƒ‰ê¸°) ëª¨ë“ˆ
â”‚   â”œâ”€â”€ A_generation.py                # Generator (ìƒì„±ê¸°) ëª¨ë“ˆ
â”‚   â”œâ”€â”€ B_retriever.py                 # Retriever (B ë²„ì „)
â”‚   â”œâ”€â”€ B_generation.py                # Generator (B ë²„ì „)
â”‚   â”œâ”€â”€ backend.py                     # ë°±ì—”ë“œ API
â”‚   â”œâ”€â”€ frontend.py                    # í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ AB_pipeline_eval.py             # A/B íŒŒì´í”„ë¼ì¸ í†µí•© í‰ê°€ ì½”ë“œ (Retrieval + Generation)
â”‚
â”œâ”€â”€ main.py                # í”„ë¡œì íŠ¸ ì‹¤í–‰ ì§„ì…ì 
â”œâ”€â”€ README.md              # í”„ë¡œì íŠ¸ ê°œìš” ë° ì‹¤í–‰ ê°€ì´ë“œ
â””â”€â”€ .gitignore             # Git ì œì™¸ ê·œì¹™
```

## 9. ì£¼ìš” ê¸°ëŠ¥

| êµ¬ë¶„          | ì„¤ëª… |
|---------------|------|
| **ì „ì²˜ë¦¬**    | PDF/HWP â†’ í…ìŠ¤íŠ¸ ë³€í™˜, ì²­í¬ ë¶„í• , ë©”íƒ€ë°ì´í„° ë¶€ì°© |
| **ì„ë² ë”©**    | SBERT, KoSimCSE ë“± ë‹¤ì–‘í•œ í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì§€ì› |
| **ì¸ë±ì‹±**    | FAISS ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„± |
| **ê²€ìƒ‰**      | Dense, Sparse, Hybrid ê²€ìƒ‰ ë°©ì‹ ì§€ì› |
| **ìƒì„±**      | OpenAI, HuggingFace ê¸°ë°˜ LLM ì‘ë‹µ ìƒì„± |
| **í‰ê°€**      | LangSmith, Cosine Similarity ê¸°ë°˜ ì„±ëŠ¥ í‰ê°€ |
| **A/B ë¹„êµ**  | Retriever/Generator êµ¬ì¡°ë³„ ì„±ëŠ¥ ë¹„êµ ë¶„ì„ |

---
## 10. í‰ê°€ ë°©ì‹ (LangSmith)

RAG ì‹œìŠ¤í…œì˜ **Retriever**ì™€ **Generator** ì„±ëŠ¥ì„ LangSmithì—ì„œ ìë™ í‰ê°€í•©ë‹ˆë‹¤.

### 10.1 ë°ì´í„° êµ¬ì¡°

`langsmith_eval_A.jsonl` ì˜ˆì‹œ:

```json
{
  "inputs":  { 
    "input": "ìŠ¤ë§ˆíŠ¸ìº í¼ìŠ¤ ê¸°ëŠ¥ì€?",
    "context": "ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ1 || ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ2"
  },
  "outputs": {
    "output": "ìŠ¤ë§ˆíŠ¸ìº í¼ìŠ¤ëŠ” ..."
  },
  "retrieved_ids": ["doc1:1:intro", "doc2:3:table"],
  "pipeline": "A"
}
```

- `inputs.input` : ì§ˆë¬¸  
- `inputs.context` : ê²€ìƒ‰ëœ ë¬¸ì„œ(ì»¨í…ìŠ¤íŠ¸)  
- `outputs.output` : ëª¨ë¸ ìƒì„± ì‘ë‹µ  
- `retrieved_ids` : ê²€ìƒ‰ëœ ë¬¸ì„œ ID  
- `pipeline` : íŒŒì´í”„ë¼ì¸ êµ¬ë¶„ê°’

### 10.2 LangSmith UIì—ì„œ í‰ê°€ ì‹¤í–‰

1. **Datasets â†’ New Dataset** ì—ì„œ `langsmith_eval_A.jsonl` ì—…ë¡œë“œ  
   - í•„ë“œ ë§¤í•‘ì€ ìë™ìœ¼ë¡œ `inputs` / `outputs` ë¡œ ì¸ì‹ë¨
2. ìƒë‹¨ **Evaluate â†’ New Evaluation** í´ë¦­  
3. **Choose Target** ë‹¨ê³„ì—ì„œ **No target function** ë° **Use dataset outputs** ì˜µì…˜ ì„ íƒ  
4. **Evaluator** ì¶”ê°€ (ì•„ë˜ í”„ë¡¬í”„íŠ¸/ìŠ¤í‚¤ë§ˆ ì‚¬ìš©)  
5. í‰ê°€ ì‹¤í–‰ â†’ ê²°ê³¼ í…Œì´ë¸”ì—ì„œ **score(0â€“5)** + **rationale(ê·¼ê±°)** í™•ì¸

### 10.3 í‰ê°€ ì¶•
RAG ì‹œìŠ¤í…œ í‰ê°€ëŠ” ë‘ ì¶•ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤
1) **ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì í•©ì„± (Retrieval Quality)**  
2) **ìƒì„± ì •í™•ì„±/ì¶©ì‹¤ì„± (Generation Faithfulness)**

### 10.3.1 ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì í•©ì„± í‰ê°€ í”„ë¡¬í”„íŠ¸

```text
You are an expert data labeler evaluating RETRIEVAL QUALITY for a RAG system.
Score the context for how well it supports answering the input question.

<Rubric (5-point scale)>
5: Context is directly relevant and sufficient to answer all parts of the question with high confidence.
4: Mostly relevant and sufficient; minor gaps but still clearly answers the question.
3: Partially relevant; covers some aspects but notable gaps/irrelevant portions.
2: Mostly irrelevant or insufficient; significant gaps to answer the question.
1: Irrelevant or misleading context; unusable for answering the question.
0: Empty or unusable content.

<Instructions>
- Read the input question and the provided context.
- Judge ONLY the context (not the model output).
- Consider directness, completeness, and lack of noise/irrelevance.
- Return a JSON object with: 
  {
    "score": <0-5 integer>,
    "rationale": "<why this score>",
    "citations": ["<exact phrases from context that justify the score>", ...]
  }
- The rationale MUST explicitly reference the cited phrases.
- If score â‰¤ 3, include at least 2 citations when possible.

<Input>
{{inputs.input}}
</Input>

<Context>
{{inputs.context}}
</Context>
```

**Feedback configuration (JSON Schema)**

```json
{
  "title": "retrieval_quality",
  "description": "Score how well the retrieved context supports answering the input question.",
  "type": "object",
  "properties": {
    "score": {
      "title": "score",
      "type": "integer",
      "minimum": 0,
      "maximum": 5
    },
    "rationale": {
      "title": "rationale",
      "type": "string",
      "minLength": 1
    },
    "citations": {
      "title": "citations",
      "type": "array",
      "items": {
        "type": "string"
      }
    }
  },
  "required": [
    "score",
    "rationale"
  ],
  "additionalProperties": false
}
```

### 10.3.2 ìƒì„± ì •í™•ì„±/ì¶©ì‹¤ì„± í‰ê°€ í”„ë¡¬í”„íŠ¸

```text
You are an expert data labeler evaluating GENERATION FAITHFULNESS and CORRECTNESS in a RAG system.
Use ONLY the provided context to verify the model output. Penalize any statements not supported by the context.

<Rubric (0â€“5)>
5: Fully correct & faithful to context; answers all parts; no unsupported claims.
4: Correct with minor omissions/ambiguities; no major unsupported claims.
3: Partially correct; some omissions or mildly unsupported claims.
2: Mostly incorrect/unfaithful; multiple unsupported/contradictory claims.
1: Incorrect/misleading; largely unsupported by context.
0: Empty/off-topic.

<Strict rules>
- Grounding: Every factual claim MUST be supported by the context. If the context is silent, the correct behavior is to say so (rewarded). Unsupported guesses are penalized.
- Normalization: Numbers/dates/units must match the context. Light arithmetic using only context is allowed; otherwise penalize.
- Contradictions: Any statement that conflicts with the context forces the score â‰¤ 2.
- Hallucination cap: If any non-trivial hallucination exists, cap the score at 3.
- Multi-part questions: Check coverage of each sub-question; missing parts lower the score.

<What to return>
Return a JSON object with these fields:
{
  "score": <0-5 integer>,
  "rationale": "<why this score; must include verbatim quotes from context>",
  "claims": [
    {"claim":"<atomic claim from output>","status":"supported|unsupported|contradicted|partial","evidence":["<context quote>", "..."]}
  ],
  "corrected_answer": "<best possible answer strictly from context; if insufficient, say 'ë¬¸ì„œì— ì •ë³´ ì—†ìŒ' and explain briefly>",
  "missing_info": ["<which needed facts are absent from context>", "..."]
}

<Input>
{{inputs.input}}
</Input>

<Context>
{{inputs.context}}
</Context>

<Output>
{{outputs.output}}
</Output>

<Process>
1) Extract atomic claims from <Output>.
2) For each claim, find exact supporting/conflicting snippets in <Context> (quote verbatim).
3) Decide status per claim and compute overall score per rubric.
4) Compose a concise "corrected_answer" using ONLY <Context>. If info is missing, state "ë¬¸ì„œì— ì •ë³´ ì—†ìŒ" and list what's missing.
5) Write a short rationale that cites key quotes and justifies the score.
```

**Feedback configuration (JSON Schema)**

```json
{
  "title": "gen_faithfulness_correctness",
  "description": "Scores generation faithfulness/correctness against provided context; includes claim-level analysis and a corrected, grounded answer.",
  "type": "object",
  "properties": {
    "score": {
      "title": "score",
      "type": "integer",
      "minimum": 0,
      "maximum": 5
    },
    "rationale": {
      "title": "rationale",
      "type": "string",
      "minLength": 1
    },
    "claims": {
      "title": "claims",
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "claim": { "type": "string" },
          "status": { "type": "string", "enum": ["supported", "unsupported", "contradicted", "partial"] },
          "evidence": {
            "type": "array",
            "items": { "type": "string" }
          }
        },
        "required": ["claim", "status"]
      }
    },
    "corrected_answer": {
      "title": "corrected_answer",
      "type": "string"
    },
    "missing_info": {
      "title": "missing_info",
      "type": "array",
      "items": { "type": "string" }
    }
  },
  "required": ["score", "rationale", "corrected_answer"],
  "additionalProperties": false
}
```