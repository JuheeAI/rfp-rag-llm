# src/frontend.py

import streamlit as st
import requests
import json


IP = "34.68.253.209"

########################################################################
# Notice íŒì—… ê¸°ëŠ¥
@st.dialog("Notice")
def show_notice():
    st.markdown(
    """
    ### RFP?

    RFP(Request for Proposal)ë€ ì œì•ˆìš”ì²­ì„œì˜ ì•½ìë¡œ, ë°œì£¼ìê°€ íŠ¹ì • ê³¼ì œ ìˆ˜í–‰ì— í•„ìš”í•œ ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í•œ ë¬¸ì„œì…ë‹ˆë‹¤.

    ---
    ### RFP Analyzer ì‚¬ìš©ë²•

    (1) ì‚¬ì´ë“œë°”ì—ì„œ 'Open Source' ë˜ëŠ” 'OpenAI' ëª¨ë¸ ì„ íƒ

    (2) 'OpenAI' ëª¨ë¸ì„ ì„ íƒí–ˆë‹¤ë©´ ìœ íš¨í•œ API í‚¤ ì…ë ¥ í•„ìš”

    (3) ì±„íŒ…ì°½ì— ë¶„ì„í•˜ê³  ì‹¶ì€ RFP ê´€ë ¨ ì§ˆë¬¸ ì…ë ¥

    ---
    ### ì§ˆë¬¸ ì˜ˆì‹œ

    - ê³ ë ¤ëŒ€í•™êµ ì°¨ì„¸ëŒ€ í¬í„¸Â·í•™ì‚¬ ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶• ì‚¬ì—… ì œì•ˆì„œ ìš”ì•½í•´ ì¤˜. ì˜ˆì‚°ë„ í•¨ê»˜ ì•Œë ¤ì¤˜.
    > (ì •ë‹µ) ì‚¬ì—…ì˜ˆì‚° : 11,270,000,000ì›


    - í•œì˜ëŒ€í•™êµ íŠ¹ì„±í™” ë§ì¶¤í˜• êµìœ¡í™˜ê²½ êµ¬ì¶• - íŠ¸ë™ìš´ì˜ í•™ì‚¬ì •ë³´ì‹œìŠ¤í…œ ê³ ë„í™” ì œì•ˆì„œ ìš”ì•½í•´ ì¤˜. ì˜ˆì‚°ë„ í•¨ê»˜ ì•Œë ¤ì¤˜.
    > (ì •ë‹µ) ì‚¬ì—…ì˜ˆì‚° : 130,000,000ì›

    """
    )
    col1, col2, col3 = st.columns([2, 1, 2])
    with col2:
        if st.button("í™•ì¸", use_container_width=True):
            st.session_state.notice_shown = True
            st.rerun()

if "notice_shown" not in st.session_state:
    show_notice()


########################################################################
# UI ì„¤ì •
st.set_page_config(layout="wide", initial_sidebar_state="expanded")
st.title("RFP Analyzer")
st.caption("[ By 404AllFound ]")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ Settings")

    model_source = st.selectbox("Select Model", ("Open Source", "OpenAI"), key="model_select")
    is_openai_selected = (model_source == "OpenAI")
    openai_api_key = st.text_input("OpenAI API Key", type="password", placeholder="", disabled=not is_openai_selected, key="api_key_input")

    st.divider()
    show_context = st.toggle("ğŸ“š Reference Check", value=True, key="show_context_toggle")
    st.divider()

    if st.button("Notice", use_container_width=True):
        show_notice()

    if st.button("Reset all chats", use_container_width=True):
        st.session_state.messages = []
        st.rerun()


########################################################################
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["role"] == "user":
            st.markdown(message["content"])
        else:
            content = message["content"]
            if st.session_state.show_context_toggle and isinstance(content, dict) and "context" in content:
                with st.expander("ğŸ“š Reference Check", expanded=False):
                    if content["context"]:
                        for doc in content["context"]:
                            source = doc.get('source', 'Unknown Source').replace('_', ' ').replace('.json', '')
                            doc_content = doc.get('content', 'ë‚´ìš© ì—†ìŒ')
                            st.write(f"ğŸ“„ {source}")
                            st.info(doc_content)
                    else:
                        st.write("ì°¸ì¡°ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.markdown(content.get("answer", "ë‹µë³€ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."))
            else:
                answer = content.get("answer") if isinstance(content, dict) else content
                st.markdown(answer)


########################################################################
# ì‚¬ìš©ì ì…ë ¥ ë° ì‘ë‹µ ì²˜ë¦¬
if prompt := st.chat_input(""):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    if is_openai_selected and not openai_api_key.startswith("sk"):
        with st.chat_message("assistant"):
            error_msg = "Please enter a valid API key."
            st.error(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})
    else:
        payload = {
            "query": prompt,
            "model_source": model_source,
            "api_key": openai_api_key if is_openai_selected else None
        }
        API_URL = f"http://{IP}:9000"

        try:
            with st.chat_message("assistant"):
                # nonlocal ëŒ€ì‹  ì‚¬ìš©í•  ë”•ì…”ë„ˆë¦¬
                shared_data = {"context": None}

                def response_generator():
                    with requests.post(f"{API_URL}/get_answer", json=payload, stream=True) as response:
                        response.raise_for_status()
                        
                        buffer = ""
                        DELIMITER = "_|||_"
                        context_processed = False
                        
                        for chunk in response.iter_content(chunk_size=None, decode_unicode=True):
                            if not context_processed:
                                buffer += chunk
                                if DELIMITER in buffer:
                                    context_json_str, llm_stream_part = buffer.split(DELIMITER, 1)
                                    # ë”•ì…”ë„ˆë¦¬ì— ì»¨í…ìŠ¤íŠ¸ ì €ì¥
                                    shared_data["context"] = json.loads(context_json_str)
                                    context_processed = True
                                    yield llm_stream_part
                            else:
                                yield chunk
                
                # í† ê¸€ì´ ì¼œì ¸ ìˆì„ ë•Œë§Œ ì°¸ì¡° ë¬¸ì„œ expanderë¥¼ ë¯¸ë¦¬ ìƒì„±
                if st.session_state.show_context_toggle:
                    context_expander = st.expander("ğŸ“š Reference Check", expanded=False)
                
                # ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
                answer_placeholder = st.empty()
                full_response = ""
                for chunk in response_generator():
                    full_response += chunk
                    answer_placeholder.markdown(full_response + "â–Œ")
                answer_placeholder.markdown(full_response)
                
                # ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚˜ê³ , í† ê¸€ì´ ì¼œì ¸ ìˆìœ¼ë©´ ì°¸ì¡° ë¬¸ì„œ ì˜ì—­ ì±„ìš°ê¸°
                if st.session_state.show_context_toggle and shared_data["context"]:
                    with context_expander:
                        for doc in shared_data["context"]:
                            source = doc.get('source', 'Unknown Source').replace('_', ' ').replace('.json', '')
                            doc_content = doc.get('content', 'ë‚´ìš© ì—†ìŒ')
                            st.write(f"ğŸ“„ {source}")
                            st.info(doc_content)

            # ì „ì²´ ëŒ€í™” ë‚´ìš©ì„ ì„¸ì…˜ ê¸°ë¡ì— ì €ì¥
            message_content = {
                "context": shared_data["context"],
                "answer": full_response
            }
            st.session_state.messages.append({"role": "assistant", "content": message_content})

        except requests.exceptions.RequestException as e:
            st.error(f"API Error: {e}")
